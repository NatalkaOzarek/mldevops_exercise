{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qSYsmgG9TN6A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class FashionMNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FashionMNISTClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vf8nB_ZITR5R",
    "outputId": "aae5559b-dbec-434c-e95b-5119f2aa5bbe"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 202kB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.73MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.92MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:17<00:00, 54.22it/s]\n",
      "100%|██████████| 938/938 [00:20<00:00, 44.75it/s]\n",
      "100%|██████████| 938/938 [00:14<00:00, 63.32it/s]\n",
      "100%|██████████| 938/938 [00:13<00:00, 67.20it/s]\n",
      "100%|██████████| 938/938 [00:14<00:00, 64.70it/s]\n",
      "100%|██████████| 938/938 [00:14<00:00, 66.50it/s]\n",
      "100%|██████████| 938/938 [00:14<00:00, 63.62it/s]\n",
      "100%|██████████| 938/938 [00:14<00:00, 65.36it/s]\n",
      "100%|██████████| 938/938 [00:13<00:00, 67.61it/s]\n",
      "100%|██████████| 938/938 [00:13<00:00, 67.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 88.76%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=tensor_transform)\n",
    "\n",
    "dataset_test = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=tensor_transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9),\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 28 * 28),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "model = AE()\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for image, _ in train_loader:\n",
    "        image = image.view(-1, 28 * 28)\n",
    "\n",
    "        reconstructed = model(image)\n",
    "        loss = loss_function(reconstructed, image)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image, _ in test_loader:\n",
    "            image = image.view(-1, 28 * 28)\n",
    "\n",
    "            reconstructed = model(image)\n",
    "            loss = loss_function(reconstructed, image)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")"
   ],
   "metadata": {
    "id": "smLBBMQHTUiB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, epochs + 1), test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_iter = iter(test_loader)\n",
    "    images, _ = next(test_iter)\n",
    "    images = images.view(-1, 28 * 28)\n",
    "    reconstructed = model(images)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(images[i].view(28, 28), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[1, i].imshow(reconstructed[i].view(28, 28), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    plt.suptitle(\"Original Images (Top Row) and Reconstructed Images (Bottom Row)\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "27APa6U7TZLt"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
